name: Sync Repository with GCS Preprod Bucket

# Execute this on changes to repository/repository/
on:
  # When a new root is published.
  push:
    branches:
      - main
    paths:
      - 'repository/repository/**'
  workflow_dispatch:

jobs:
  sync:
    runs-on: ubuntu-20.04
    permissions:
      id-token: 'write'
    steps:
      - uses: actions/checkout@2541b1294d2704b0964813337f33b291d3f8596b # v2.4.0
        with:
          fetch-depth: 0
      - uses: actions/setup-go@84cbf8094393cdc5fe1fe1671ff2647332956b1a # v2.2.0
        with:
          go-version: 1.17.x
      - uses: google-github-actions/setup-gcloud@877d4953d2c70a0ba7ef3290ae968eb24af233bb # v0.5.1
        with:
          project_id: project-rekor
          install_components: alpha
      # Setup OIDC->SA auth
      - uses: google-github-actions/auth@ceee102ec2387dd9e844e01b530ccd4ec87ce955 # v0.7.2
        id: auth
        with:
          token_format: 'access_token'
          workload_identity_provider: 'projects/237800849078/locations/global/workloadIdentityPools/root-signing-pool/providers/sigstore-root'
          service_account: 'sigstore-root-signing@project-rekor.iam.gserviceaccount.com'
          create_credentials_file: true
      - name: Login
        run: |
          gcloud auth login --brief --cred-file="${{ steps.auth.outputs.credentials_file_path }}"
          gcloud auth list
      # Sync
      # TODO(297): Switch to stable gcloud API, use rsync when available
      - name: sync
        run: |
          check_expiration() {
              expiry=$(jq -r '.signed.expires' $1)
              expires=$(date -d $expiry +%s)
              current=$(date +%s)
              if (( expires < current )); then
                  echo "Detected expired metadata file $1 at $expiry!"
                  exit 1
              fi;
          }

          # Upload all but TUF timestamp. Once timestamp is uploaded, all other files must have been uploaded.
          for f in $(ls repository/repository/ -I *timestamp.json)
          do
            # Check for expiration if this is a non-versioned metadata file. 
            # Versioned metadata like 1.root.json may be expired.
            # TODO(asraa): When consistent snapshots are enabled, this logic must be changed so that
            # only old versioned metadata can be expired.
            if [[ $f == [^0-9]*.json ]]; then
                check_expiration repository/repository/$f
            fi;

            gcloud alpha --quiet storage cp --cache-control=no-store -r repository/repository/$f gs://sigstore-preprod-tuf-root/
          done

          # Upload timestamp after checking latest timestamp expiration
          check_expiration repository/repository/timestamp.json
          gcloud alpha --quiet storage cp --cache-control=no-store -r repository/repository/*timestamp.json gs://sigstore-preprod-tuf-root/

          # delete any files present in sigstore-preprod-tuf-root not in repository/repository
          gcloud alpha --quiet storage cp -r gs://sigstore-preprod-tuf-root/ .

          diff -qr repository/repository sigstore-preprod-tuf-root | while read l; do
            if [[ $l =~ "Only in sigstore-preprod-tuf-root" ]]; then
              path=$(python3 -c "import re; s='$l'; pattern=r'^Only in sigstore-preprod-tuf-root(\/?)(.*): (.*)$'; match=re.search(pattern, s); print('/'.join([match.group(2), match.group(3)]).lstrip('/'))")
              gcloud alpha --quiet storage rm gs://sigstore-preprod-tuf-root/$path
            fi;
          done
